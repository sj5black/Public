import streamlit as st
import os
import json
import uuid
from datetime import datetime
from typing import List, Dict, Any
import pandas as pd
from dotenv import load_dotenv
load_dotenv()

# RAG ê´€ë ¨ imports
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
from langchain_community.document_loaders import PyPDFLoader, TextLoader
from langchain.schema import Document
import tempfile

# API í‚¤ ì„¤ì •
openai_api_key = os.getenv("OPENAI_API_KEY")
if not openai_api_key:
    st.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()
    
# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë¬¸ì„œê²€ìƒ‰ ë„ìš°ë¯¸ ì±—ë´‡",
    page_icon="",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'chat_sessions' not in st.session_state:
    st.session_state.chat_sessions = {}
if 'current_session_id' not in st.session_state:
    st.session_state.current_session_id = None
if 'vectorstore' not in st.session_state:
    st.session_state.vectorstore = None
if 'conversation_chain' not in st.session_state:
    st.session_state.conversation_chain = None
if 'uploaded_docs' not in st.session_state:
    st.session_state.uploaded_docs = []


class ChatSession:
    def __init__(self, session_id: str, name: str):
        self.session_id = session_id
        self.name = name
        self.messages = []
        self.created_at = datetime.now()
        self.updated_at = datetime.now()
    
    def add_message(self, role: str, content: str, sources: List[str] = None):
        message = {
            "role": role,
            "content": content,
            "timestamp": datetime.now().isoformat(),
            "sources": sources or []
        }
        self.messages.append(message)
        self.updated_at = datetime.now()
    
    def to_dict(self):
        return {
            "session_id": self.session_id,
            "name": self.name,
            "messages": self.messages,
            "created_at": self.created_at.isoformat(),
            "updated_at": self.updated_at.isoformat()
        }

def load_sessions():
    """ì €ì¥ëœ ì„¸ì…˜ë“¤ì„ ë¡œë“œ"""
    sessions_file = "chat_sessions.json"
    if os.path.exists(sessions_file):
        try:
            with open(sessions_file, 'r', encoding='utf-8') as f:
                sessions_data = json.load(f)
            
            sessions = {}
            for session_data in sessions_data:
                session = ChatSession(
                    session_data['session_id'],
                    session_data['name']
                )
                session.messages = session_data['messages']
                session.created_at = datetime.fromisoformat(session_data['created_at'])
                session.updated_at = datetime.fromisoformat(session_data['updated_at'])
                sessions[session.session_id] = session
            
            return sessions
        except Exception as e:
            st.error(f"ì„¸ì…˜ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
            return {}
    return {}

def save_sessions():
    """ì„¸ì…˜ë“¤ì„ íŒŒì¼ì— ì €ì¥"""
    sessions_file = "chat_sessions.json"
    try:
        sessions_data = [session.to_dict() for session in st.session_state.chat_sessions.values()]
        with open(sessions_file, 'w', encoding='utf-8') as f:
            json.dump(sessions_data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        st.error(f"ì„¸ì…˜ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")

def create_new_session():
    """ìƒˆë¡œìš´ ì±„íŒ… ì„¸ì…˜ ìƒì„±"""
    session_id = str(uuid.uuid4())
    session_name = f"ì„¸ì…˜ {len(st.session_state.chat_sessions) + 1}"
    new_session = ChatSession(session_id, session_name)
    st.session_state.chat_sessions[session_id] = new_session
    st.session_state.current_session_id = session_id
    save_sessions()
    return session_id

# 1. ë°ì´í„° ë¡œë“œ
def load_documents(uploaded_files):
    """ì—…ë¡œë“œëœ íŒŒì¼ë“¤ì„ ë¬¸ì„œë¡œ ë³€í™˜"""
    documents = []
    
    for uploaded_file in uploaded_files:
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix=f".{uploaded_file.name.split('.')[-1]}") as tmp_file:
            tmp_file.write(uploaded_file.read())
            tmp_file_path = tmp_file.name
        
        try:
            if uploaded_file.name.endswith('.pdf'):
                loader = PyPDFLoader(tmp_file_path)
                docs = loader.load()
            elif uploaded_file.name.endswith('.txt'):
                # ì—¬ëŸ¬ ì¸ì½”ë”©ì„ ì‹œë„í•´ë³´ê¸°
                encodings = ['utf-8', 'cp949', 'euc-kr', 'latin-1']
                docs = None
                
                for encoding in encodings:
                    try:
                        # íŒŒì¼ì´ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
                        if not os.path.exists(tmp_file_path):
                            st.error(f"ì„ì‹œ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {tmp_file_path}")
                            break
                            
                        loader = TextLoader(tmp_file_path, encoding=encoding)
                        docs = loader.load()
                        st.success(f"íŒŒì¼ '{uploaded_file.name}'ì„ {encoding} ì¸ì½”ë”©ìœ¼ë¡œ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
                        break
                    except UnicodeDecodeError:
                        continue
                    except Exception as e:
                        st.warning(f"ì¸ì½”ë”© {encoding}ìœ¼ë¡œ íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
                        continue
                
                if docs is None:
                    st.error(f"íŒŒì¼ '{uploaded_file.name}'ì˜ ì¸ì½”ë”©ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    continue
            else:
                st.warning(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {uploaded_file.name}")
                continue
            
            # ë¬¸ì„œì— ë©”íƒ€ë°ì´í„° ì¶”ê°€
            for doc in docs:
                doc.metadata['source'] = uploaded_file.name
            
            documents.extend(docs)
            
        except Exception as e:
            st.error(f"íŒŒì¼ '{uploaded_file.name}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        finally:
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            if os.path.exists(tmp_file_path):
                os.unlink(tmp_file_path)
    
    return documents

# 2 to 4. ë°ì´í„° ë¶„í•  + ì„ë² ë”© + ë²¡í„°DB ì €ì¥
def create_vectorstore(documents):
    """ë¬¸ì„œë“¤ë¡œë¶€í„° ë²¡í„° ìŠ¤í† ì–´ ìƒì„±"""
    if not documents:
        return None
    
    # 2. í…ìŠ¤íŠ¸ ë¶„í• 
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200,
        length_function=len
    )
    
    chunks = text_splitter.split_documents(documents)
    
    # 3. ì„ë² ë”© ìƒì„±
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    
    # 4. FAISS ë²¡í„° ìŠ¤í† ì–´ ìƒì„± í›„ ì €ì¥
    vectorstore = FAISS.from_documents(chunks, embeddings)
    
    return vectorstore

# 5. LangChain ìƒì„±
def create_conversation_chain(vectorstore, openai_api_key):
    """ëŒ€í™”í˜• ê²€ìƒ‰ ì²´ì¸ ìƒì„±"""
    if not vectorstore:
        return None
    
    llm = ChatOpenAI(
        model="gpt-4-turbo-preview",
        temperature=0.7,
        openai_api_key=openai_api_key
    )
    
    # ë©”ëª¨ë¦¬ ì„¤ì •
    memory = ConversationBufferMemory(
        memory_key="chat_history",
        return_messages=True,
        output_key="answer"
    )
    
    # ëŒ€í™”í˜• ê²€ìƒ‰ ì²´ì¸ ìƒì„±
    conversation_chain = ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=vectorstore.as_retriever(search_kwargs={"k": 3}),
        memory=memory,
        return_source_documents=True,
        verbose=True
    )
    
    return conversation_chain

def sync_memory_with_session(conversation_chain, chat_session):
    """ì„¸ì…˜ì— ì €ì¥ëœ ë©”ì‹œì§€ë¥¼ LangChain ë©”ëª¨ë¦¬ì— ë°˜ì˜"""
    if not conversation_chain or not chat_session:
        return
    
    memory = conversation_chain.memory
    memory.clear()  # ê¸°ì¡´ ë©”ëª¨ë¦¬ ì´ˆê¸°í™”
    
    for msg in chat_session.messages:
        if msg["role"] == "user":
            memory.chat_memory.add_user_message(msg["content"])
        elif msg["role"] == "assistant":
            memory.chat_memory.add_ai_message(msg["content"])
            
def main():
    st.title("ğŸ“š RAG ë¬¸ì„œ ì±—ë´‡")
    st.markdown("PDF/TXT ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ê³  ì§ˆë¬¸í•´ë³´ì„¸ìš”!")
    
    # ì‚¬ì´ë“œë°” - ì„¸ì…˜ ê´€ë¦¬
    with st.sidebar:
        st.header("ğŸ’¬ ì±„íŒ… ì„¸ì…˜")
        
        # ì„¸ì…˜ ë¡œë“œ
        if not st.session_state.chat_sessions:
            st.session_state.chat_sessions = load_sessions()
        
        # ìƒˆ ì„¸ì…˜ ìƒì„± ë²„íŠ¼
        if st.button("ğŸ†• ìƒˆ ì„¸ì…˜ ìƒì„±"):
            create_new_session()
            st.rerun()
        
        # ê¸°ì¡´ ì„¸ì…˜ ëª©ë¡
        if st.session_state.chat_sessions:
            st.subheader("ê¸°ì¡´ ì„¸ì…˜")
            for session_id, session in st.session_state.chat_sessions.items():
                col1, col2 = st.columns([3, 1])
                with col1:
                    if st.button(
                        f"{session.name} ({len(session.messages)})",
                        key=f"session_{session_id}",
                        use_container_width=True
                    ):
                        st.session_state.current_session_id = session_id
                        # ğŸ”‘ ëŒ€í™” íˆìŠ¤í† ë¦¬ ë³µì›
                        sync_memory_with_session(st.session_state.conversation_chain, st.session_state.chat_sessions[session_id])
                        st.rerun()
                with col2:
                    if st.button("ğŸ—‘ï¸", key=f"delete_{session_id}"):
                        del st.session_state.chat_sessions[session_id]
                        if st.session_state.current_session_id == session_id:
                            st.session_state.current_session_id = None
                        save_sessions()
                        st.rerun()
        
        st.divider()
        
        # ë¬¸ì„œ ì—…ë¡œë“œ
        st.subheader("ğŸ“„ ê´€ë ¨ ë¬¸ì„œ")
        uploaded_files = st.file_uploader(
            "PDF ë˜ëŠ” TXT íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”",
            type=['pdf', 'txt'],
            accept_multiple_files=True
        )
        
        if uploaded_files:
            if st.button("ë¬¸ì„œ ì—…ë¡œë“œ"):
                with st.spinner("ì—…ë¡œë“œí•œ ë¬¸ì„œë¥¼ í•™ìŠµí•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                    # ë¬¸ì„œ ë¡œë“œ
                    documents = load_documents(uploaded_files)
                    st.session_state.uploaded_docs = [f.name for f in uploaded_files]
                    
                    if documents:
                        # ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
                        vectorstore = create_vectorstore(documents)
                        st.session_state.vectorstore = vectorstore
                        
                        # ëŒ€í™” ì²´ì¸ ìƒì„±
                        conversation_chain = create_conversation_chain(vectorstore, openai_api_key)
                        st.session_state.conversation_chain = conversation_chain
                        
                        st.success(f"âœ… {len(documents)}ê°œì˜ ë¬¸ì„œê°€ ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    else:
                        st.error("ë¬¸ì„œë¥¼ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì—…ë¡œë“œëœ ë¬¸ì„œ í‘œì‹œ
        if st.session_state.uploaded_docs:
            st.subheader("ğŸ“‹ ì—…ë¡œë“œëœ ë¬¸ì„œ")
            for doc_name in st.session_state.uploaded_docs:
                st.text(f"â€¢ {doc_name}")
    
    # ë©”ì¸ ì˜ì—­ - ì±„íŒ…
    if not st.session_state.conversation_chain:
        st.info("ğŸ“„ ì‚¬ì´ë“œë°”ì—ì„œ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ê³  ì²˜ë¦¬í•´ì£¼ì„¸ìš”.")
        return
    
    # í˜„ì¬ ì„¸ì…˜ì´ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
    if not st.session_state.current_session_id:
        create_new_session()
    
    current_session = st.session_state.chat_sessions.get(st.session_state.current_session_id)
    if not current_session:
        st.error("ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìƒˆ ì„¸ì…˜ì„ ìƒì„±í•´ì£¼ì„¸ìš”.")
        return
    
    # ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ
    st.subheader(f"ğŸ’¬ {current_session.name}")
    
    # ë©”ì‹œì§€ í‘œì‹œ ì˜ì—­
    chat_container = st.container()
    
    with chat_container:
        for message in current_session.messages:
            if message["role"] == "user":
                with st.chat_message("user"):
                    st.write(message["content"])
            else:
                with st.chat_message("assistant"):
                    st.write(message["content"])
                    if message.get("sources"):
                        with st.expander("ğŸ“š ì¶œì²˜"):
                            for i, source in enumerate(message["sources"], 1):
                                st.write(f"{i}. {source}")
    
    # ì§ˆë¬¸ ì…ë ¥
    user_question = st.chat_input("ë¬¸ì„œì— ëŒ€í•´ ì§ˆë¬¸í•´ë³´ì„¸ìš”...")
    
    if user_question:
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        current_session.add_message("user", user_question)
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
        with st.chat_message("user"):
            st.write(user_question)
        
        # AI ì‘ë‹µ ìƒì„±
        with st.chat_message("assistant"):
            with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                try:
                    response = st.session_state.conversation_chain({"question": user_question})
                    answer = response["answer"]
                    source_docs = response.get("source_documents", [])
                    
                    # ë‹µë³€ í‘œì‹œ
                    st.write(answer)
                    
                    # ì¶œì²˜ ì •ë³´ ìˆ˜ì§‘
                    sources = []
                    if source_docs:
                        with st.expander("ğŸ“š ì¶œì²˜"):
                            for i, doc in enumerate(source_docs, 1):
                                source_name = doc.metadata.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ')
                                page = doc.metadata.get('page', '')
                                page_info = f" (í˜ì´ì§€ {page + 1})" if page != '' else ""
                                source_text = f"{source_name}{page_info}"
                                sources.append(source_text)
                                
                                st.write(f"**{i}. {source_text}**")
                                st.write(doc.page_content[:300] + "..." if len(doc.page_content) > 300 else doc.page_content)
                                st.divider()
                    
                    # AI ë©”ì‹œì§€ ì¶”ê°€
                    current_session.add_message("assistant", answer, sources)
                    
                except Exception as e:
                    error_message = f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
                    st.error(error_message)
                    current_session.add_message("assistant", error_message)
        
        # ì„¸ì…˜ ì €ì¥
        save_sessions()
        st.rerun()

if __name__ == "__main__":
    main()