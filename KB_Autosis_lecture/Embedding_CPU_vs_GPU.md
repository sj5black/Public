# ğŸ§  ì„ë² ë”©(Embedding)ì€ CPU, LLMì€ GPUì—ì„œ êµ¬ë™í•˜ëŠ” ì´ìœ 

## 1ï¸âƒ£ ì„ë² ë”© vs LLM êµ¬ë™ ì›ë¦¬

| êµ¬ë¶„ | ì„ë² ë”©(Embedding Model) | LLM(Language Model) |
|------|------------------------|---------------------|
| **ì…ë ¥/ì¶œë ¥** | ë¬¸ì¥ â†’ ë²¡í„° | ë¬¸ì¥ â†’ ë‹¤ìŒ ë‹¨ì–´ í™•ë¥  |
| **ì£¼ìš” ì—°ì‚°** | í”¼ì²˜ ì¶”ì¶œ (ë²¡í„° ìƒì„±) | ì‹œí€€ìŠ¤ ìƒì„± (ë””ì½”ë”© ë°˜ë³µ) |
| **ì—°ì‚° í˜•íƒœ** | 1íšŒ forward pass | í† í° ë‹¨ìœ„ ë°˜ë³µ ì¶”ë¡  |
| **ìì› ìš”êµ¬ë„** | CPUë¡œ ì¶©ë¶„ | GPU í•„ìš” |
| **ë³‘ë ¬ì„± ìš”êµ¬ë„** | ë‚®ìŒ | ë§¤ìš° ë†’ìŒ |

---

## 2ï¸âƒ£ ë‚´ë¶€ êµ¬ì¡°

### ğŸ”¹ ì„ë² ë”© (Encoder ê¸°ë°˜)
```
ë¬¸ì¥ ì…ë ¥ â†’ í† í°í™” â†’ [Encoder Layers] â†’ í‰ê· í’€ë§ â†’ ë²¡í„° ì¶œë ¥
```

### ğŸ”¹ LLM (Decoder ê¸°ë°˜)
```
ì…ë ¥ ë¬¸ì¥ â†’ Self-Attention ë°˜ë³µ â†’ ë‹¤ìŒ ë‹¨ì–´ ì˜ˆì¸¡ â†’ ë°˜ë³µ ë””ì½”ë”©
```

---

## 3ï¸âƒ£ CPU vs GPU ì—°ì‚° ë°©ì‹

| êµ¬ë¶„ | CPU | GPU |
|------|------|------|
| **ì½”ì–´ ê°œìˆ˜** | ìˆ˜ì‹­ ê°œ | ìˆ˜ì²œ~ìˆ˜ë§Œ ê°œ |
| **íŠ¹í™” ì˜ì—­** | ìˆœì°¨ ì—°ì‚°, ì œì–´ ë¡œì§ | ë³‘ë ¬ ë²¡í„°/í–‰ë ¬ ì—°ì‚° |
| **ì í•© ì‘ì—…** | ì„ë² ë”©, ì¸ë±ì‹± | LLM ì¶”ë¡ , Attention |
| **ë©”ëª¨ë¦¬ êµ¬ì¡°** | ìºì‹œ ì¤‘ì‹¬ | GDDR/HBM ê³ ëŒ€ì—­í­ |
| **ëŒ€í‘œ ì‘ì—… ì˜ˆì‹œ** | í…ìŠ¤íŠ¸ ë²¡í„°í™” | 70B íŒŒë¼ë¯¸í„° ì¶”ë¡  |

---

## 4ï¸âƒ£ ì‹¤ì œ ì½”ë“œ ë¹„êµ

### âœ… CPU ì„ë² ë”©
```python
from sentence_transformers import SentenceTransformer
model = SentenceTransformer("intfloat/multilingual-e5-base", device="cpu")
embeddings = model.encode(["AI is changing the world."])
print(embeddings.shape)
```

### âœ… GPU LLM ì¶”ë¡ 
```python
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

tok = AutoTokenizer.from_pretrained("meta-llama/Llama-3-8B-Instruct")
model = AutoModelForCausalLM.from_pretrained(
    "meta-llama/Llama-3-8B-Instruct",
    torch_dtype=torch.float16,
    device_map="auto"
)
inputs = tok("Explain CPU vs GPU.", return_tensors="pt").to("cuda")
print(tok.decode(model.generate(**inputs, max_new_tokens=50)[0], skip_special_tokens=True))
```

---

## 5ï¸âƒ£ ì„ë² ë”©ê³¼ LLM ë¶„ë¦¬ ì‹¤í–‰ ì´ìœ 

| ì´ìœ  | ì„¤ëª… |
|------|------|
| **VRAM ì ˆì•½** | ì„ë² ë”©ì€ CPUì—ì„œ, ìƒì„±ì€ GPUì—ì„œ ë¶„ë¦¬ |
| **ì†ë„ íš¨ìœ¨** | LLM ìƒì„± ë‹¨ê³„ë§Œ GPU ë³‘ë ¬ ì²˜ë¦¬ |
| **ìì› ë¶„ì‚°** | CPU ì„œë²„ëŠ” ë²¡í„°í™”, GPU ì„œë²„ëŠ” ìƒì„± ë‹´ë‹¹ |
| **RAG ì•„í‚¤í…ì²˜ ì í•©** | ê²€ìƒ‰(Retriever)ì€ CPU, ìƒì„±(Generator)ì€ GPU |

---

## 6ï¸âƒ£ ì „ì²´ êµ¬ì¡° ìš”ì•½

```
ì‚¬ìš©ì ì§ˆë¬¸
   â†“
[CPU] ì„ë² ë”© â†’ ë²¡í„° ê²€ìƒ‰
   â†“
[GPU] LLM â†’ ë‹µë³€ ìƒì„±
   â†“
ì‘ë‹µ ì¶œë ¥
```

---

## ğŸ§­ ìš”ì•½ ë„í‘œ

| êµ¬ë¶„ | CPU (Embedding/ê²€ìƒ‰) | GPU (LLM ìƒì„±) |
|------|----------------------|----------------|
| **ì—­í• ** | ë¬¸ì„œ ë²¡í„°í™”, ì¸ë±ì‹± | ë‹µë³€ ìƒì„± |
| **í•„ìš”ì„±** | ë‹¨ìˆœ Forward Pass | ë°˜ë³µì  Attention |
| **íš¨ìœ¨ì„±** | ì €ë¹„ìš© | ê³ ì† ë³‘ë ¬ ì—°ì‚° |
| **RAGì—ì„œì˜ ìœ„ì¹˜** | Retriever | Generator |
